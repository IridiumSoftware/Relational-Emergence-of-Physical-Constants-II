import random
import pandas as pd
from tqdm import tqdm
from Appendix_A_relational_bootstrap import run_toy_model, extract_dark_halos

random.seed(42)

def run_variant(mode, N=10000, STEPS=600, DECAY=0.99995, NOISE=0.03):
    """Four qualitatively different (M,R)-realizations."""
    G = nx.Graph()
    G.add_nodes_from(range(N))
    for _ in range(4 * N):
        u, v = random.sample(range(N), 2)
        if u != v and not G.has_edge(u, v):
            G.add_edge(u, v, weight=random.uniform(0.1, 1.0))
    
    for s in range(STEPS):
        nodes = list(G.nodes())
        energies = [sum(d.get('weight', 0) for _, _, d in G.edges(n, data=True)) for n in nodes]
        total_e = sum(energies) or 1.0
        probs = [e / total_e for e in energies]
        active = random.choices(nodes, weights=probs, k=max(1, int(0.12 * N)))
        
        for node in set(active):
            energy = sum(d.get('weight', 0) for _, _, d in G.edges(node, data=True))
            if energy > 1e-10:
                candidates = list(G.nodes())
                if mode == 'base' or mode == 'repair':  # energy-weighted
                    weights = [G.degree(n) + 1 for n in candidates]
                elif mode == 'event':  # event-driven (random subset)
                    weights = [1 if random.random() < 0.2 else 0.01 for _ in candidates]
                else:  # chiral spinor (modulated by energy parity)
                    weights = [(energy % 3 + 1) for _ in candidates]
                nbr = random.choices(candidates, weights=weights, k=1)[0]
                if node != nbr and not G.has_edge(node, nbr):
                    G.add_edge(node, nbr, weight=energy / 2.0)
        
        # Common dissipation + noise
        for u, v, d in list(G.edges(data=True)):
            d['weight'] *= DECAY
            if d['weight'] < 1e-6:
                G.remove_edge(u, v)
        
        edges_list = list(G.edges())
        perturb_n = max(1, int(NOISE * len(edges_list)))
        for _ in range(perturb_n):
            if edges_list:
                u, v = random.choice(edges_list)
                if G.has_edge(u, v):
                    G[u][v]['weight'] *= random.uniform(0.94, 1.06)
                    if G[u][v]['weight'] < 1e-6:
                        G.remove_edge(u, v)
    
    # Metrics + dark fraction
    path = sum(nx.shortest_path_length(G, random.choice(list(G.nodes())), random.choice(list(G.nodes()))) for _ in range(200)) / 200
    min_w = min((d['weight'] for _, _, d in G.edges(data=True)), default=0)
    clust = nx.average_clustering(G)
    dark = extract_dark_halos(G, min_w)
    
    return {
        'Variant': mode,
        'Avg Path': round(path, 2),
        'Clustering': round(clust, 3),
        'Min Weight': round(min_w, 4),
        'Emergent ℏ (×10^{-35})': round(min_w * (1.616255e-35**2 * 2.176434e-8 / 5.391247e-44) * 1e35, 2),
        'Emergent G (×10^{-11})': round(clust * (1.616255e-35**3 / (2.176434e-8 * 5.391247e-44**2)) * 1e11, 2),
        'Dark Fraction': dark['dark_fraction']
    }

# Run 3 independent runs per variant
variants = ['base', 'event', 'repair', 'chiral']
results = []
print("Running universality suite...")
for v_idx, v in enumerate(variants):
    for run in range(3):
        random.seed(42 + run + v_idx * 10)
        res = run_variant(v)
        results.append(res)

df = pd.DataFrame(results)
grouped = df.groupby('Variant').mean().round(3)
print(grouped)
df.to_csv('universality_table2_raw.csv', index=False)
grouped.to_csv('universality_table2_averaged.csv', index=True)
print("Table 2 reproduced and saved.")
