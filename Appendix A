import networkx as nx
import random
import pandas as pd
import matplotlib.pyplot as plt
from tqdm import tqdm  # optional but nice

random.seed(42)

# Planck prefactors (used for emergent constants)
PLANCK_LENGTH = 1.616255e-35
PLANCK_TIME = 5.391247e-44
PLANCK_MASS = 2.176434e-8
PREF_HBAR = PLANCK_LENGTH**2 * PLANCK_MASS / PLANCK_TIME
PREF_G = PLANCK_LENGTH**3 / (PLANCK_MASS * PLANCK_TIME**2)

def run_toy_model(N=10000, STEPS=600, NOISE=0.03, DECAY=0.99995):
    """Core non-equilibrium bootstrap obeying strict (M,R)-closure.
    Nodes produce edges (bootstrap). Edges produce dissipation + noise (repair)."""
    G = nx.Graph()
    G.add_nodes_from(range(N))
    # Initial random edges
    for _ in range(4 * N):
        u, v = random.sample(range(N), 2)
        if u != v and not G.has_edge(u, v):
            G.add_edge(u, v, weight=random.uniform(0.1, 1.0))

    for s in tqdm(range(STEPS), desc="Bootstrap steps"):
        # Energy-weighted preferential attachment (nodes produce edges)
        nodes = list(G.nodes())
        energies = [sum(d.get('weight', 0) for _, _, d in G.edges(n, data=True)) for n in nodes]
        total_e = sum(energies) or 1.0
        probs = [e / total_e for e in energies]
        active = random.choices(nodes, weights=probs, k=max(1, int(0.12 * N)))

        for node in set(active):
            energy = sum(d.get('weight', 0) for _, _, d in G.edges(node, data=True))
            if energy > 1e-10:
                candidates = list(G.nodes())
                weights = [G.degree(n) + 1 for n in candidates]
                nbr = random.choices(candidates, weights=weights, k=1)[0]
                if node != nbr and not G.has_edge(node, nbr):
                    G.add_edge(node, nbr, weight=energy / 2.0)

        # Edges produce dissipation & repair (strict closure)
        for u, v, d in list(G.edges(data=True)):
            d['weight'] *= DECAY
            if d['weight'] < 1e-6:
                G.remove_edge(u, v)

        # Noise (McClure-style stochasticity)
        edges_list = list(G.edges())
        perturb_n = max(1, int(NOISE * len(edges_list)))
        for _ in range(perturb_n):
            if edges_list:
                u, v = random.choice(edges_list)
                if G.has_edge(u, v):
                    G[u][v]['weight'] *= random.uniform(0.94, 1.06)
                    if G[u][v]['weight'] < 1e-6:
                        G.remove_edge(u, v)

    # Metrics (robust to disconnects)
    if nx.is_connected(G) and N <= 500:
        path_len = nx.average_shortest_path_length(G)
    else:
        samples = min(400, N * 8)
        path_len = 0.0
        count = 0
        nodes_l = list(G.nodes())
        for _ in range(samples):
            u, v = random.sample(nodes_l, 2)
            try:
                path_len += nx.shortest_path_length(G, u, v)
                count += 1
            except (nx.NetworkXNoPath, nx.NodeNotFound):
                pass
        path_len = path_len / count if count > 0 else float('nan')

    min_w = min((d['weight'] for _, _, d in G.edges(data=True)), default=0.0)
    clust = nx.average_clustering(G)

    return G, {
        'nodes': N,
        'path_len': round(path_len, 2),
        'min_w': round(min_w, 4),
        'clust': round(clust, 3),
        'hbar': min_w * PREF_HBAR,
        'G': clust * PREF_G
    }

def extract_dark_halos(G, min_w, clust_threshold=0.7):
    """High-clustering (>0.7) subgraphs = dark-matter halos (Kauffman adjacent-possible closure)."""
    halos = []
    visited = set()
    for node in G.nodes():
        if node in visited:
            continue
        local_nodes = list(nx.single_source_shortest_path_length(G, node, cutoff=3).keys())
        if len(local_nodes) < 5:
            continue
        subG = G.subgraph(local_nodes)
        local_clust = nx.average_clustering(subG)
        if local_clust > clust_threshold:
            halo_mass = sum(G.degree(n) for n in local_nodes) * min_w
            halos.append({'center': node, 'size': len(local_nodes), 'clust': round(local_clust, 3), 'mass_proxy': round(halo_mass, 4)})
            visited.update(local_nodes)
    total_mass = sum(G.degree(n) for n in G.nodes()) * min_w
    dark_fraction = sum(h['mass_proxy'] for h in halos) / total_mass if total_mass > 0 else 0.0
    return {'halos': halos, 'dark_fraction': round(dark_fraction, 3), 'num_halos': len(halos)}

# Example run + 2D dark-halo viz (for quick check)
if __name__ == "__main__":
    G, metrics = run_toy_model()
    dark = extract_dark_halos(G, metrics['min_w'])
    print("Toy model metrics:", metrics)
    print("Dark-matter fraction:", dark['dark_fraction'])

    # 2D viz (Appendix C does full 3D)
    pos = nx.spring_layout(G, seed=42)
    halo_nodes = set()
    for h in dark['halos']:
        halo_nodes.update(nx.single_source_shortest_path_length(G, h['center'], cutoff=3).keys())
    node_color = ['red' if n in halo_nodes else 'blue' for n in G.nodes()]
    nx.draw(G, pos, node_color=node_color, node_size=30, edge_color='gray', alpha=0.6, with_labels=False)
    plt.title('Emergent Dark-Matter Halos (red = clustering > 0.7)')
    plt.show()
