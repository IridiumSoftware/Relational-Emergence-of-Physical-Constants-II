import networkx as nx
import random
import pandas as pd
import time

random.seed(42)
PLANCK_LENGTH = 1.616255e-35
PLANCK_TIME   = 5.391247e-44
PLANCK_MASS   = 2.176434e-8
PREF_HBAR = PLANCK_LENGTH**2 * PLANCK_MASS / PLANCK_TIME
PREF_G    = PLANCK_LENGTH**3 / (PLANCK_MASS * PLANCK_TIME**2)
C_PLANCK  = PLANCK_LENGTH / PLANCK_TIME

def run_toy_model(N=10000, STEPS=600, ENERGY_THRESHOLD=1e-10, NOISE=0.03, DECAY=0.99995):
    G = nx.Graph()
    G.add_nodes_from(range(N))
    for _ in range(4 * N):
        u, v = random.sample(range(N), 2)
        if u != v and not G.has_edge(u, v):
            G.add_edge(u, v, weight=random.uniform(0.1, 1.0))
    
    for s in range(STEPS):
        nodes = list(G.nodes())
        energies = [sum(d.get('weight', 0) for _, _, d in G.edges(n, data=True)) for n in nodes]
        total_e = sum(energies) or 1.0
        probs = [e / total_e for e in energies]
        active_count = max(1, int(0.12 * N))
        active = random.choices(nodes, weights=probs, k=active_count)
        
        for node in set(active):
            energy = sum(d.get('weight', 0) for _, _, d in G.edges(node, data=True))
            if energy > ENERGY_THRESHOLD:
                candidates = list(G.nodes())
                weights = [G.degree(n) + 1 for n in candidates]
                nbr = random.choices(candidates, weights=weights, k=1)[0]
                if node != nbr and not G.has_edge(node, nbr):
                    G.add_edge(node, nbr, weight=energy / 2.0)
        
        for u, v, d in list(G.edges(data=True)):
            d['weight'] *= DECAY
            if d['weight'] < 1e-6:
                G.remove_edge(u, v)
        
        edges_list = list(G.edges())
        perturb_n = max(1, int(NOISE * len(edges_list)))
        for _ in range(perturb_n):
            if edges_list:
                u, v = random.choice(edges_list)
                if G.has_edge(u, v):
                    d = G[u][v]
                    d['weight'] *= random.uniform(0.94, 1.06)
                    if d['weight'] < 1e-6:
                        G.remove_edge(u, v)
    
    # Metrics
    if N <= 500:
        path_len = nx.average_shortest_path_length(G)
    else:
        samples = min(400, N * 8)
        path_len = 0.0
        count = 0
        nodes_l = list(G.nodes())
        for _ in range(samples):
            u, v = random.sample(nodes_l, 2)
            try:
                path_len += nx.shortest_path_length(G, u, v)
                count += 1
            except nx.NetworkXNoPath:
                pass
        path_len = path_len / count if count > 0 else float('nan')
    
    min_w = min((d['weight'] for _, _, d in G.edges(data=True)), default=0.0)
    clust = nx.average_clustering(G)
    
    return G, {
        'nodes': N,
        'path_len': round(path_len, 2),
        'min_w': round(min_w, 4),
        'clust': round(clust, 3),
        'hbar': min_w * PREF_HBAR,
        'G': clust * PREF_G
    }

def extract_dark_halos(G, min_w, clust_threshold=0.7):
    halos = []
    visited = set()
    for node in G.nodes():
        if node in visited:
            continue
        local_nodes = list(nx.single_source_shortest_path_length(G, node, cutoff=3).keys())
        if len(local_nodes) < 5:
            continue
        subG = G.subgraph(local_nodes)
        local_clust = nx.average_clustering(subG)
        if local_clust > clust_threshold:
            halo_mass = sum(G.degree(n) for n in local_nodes) * min_w
            halos.append({'center': node, 'size': len(local_nodes), 'clust': round(local_clust, 3), 'mass_proxy': round(halo_mass, 4)})
            visited.update(local_nodes)
    total_mass = sum(G.degree(n) for n in G.nodes()) * min_w
    dark_fraction = sum(h['mass_proxy'] for h in halos) / total_mass if total_mass > 0 else 0.0
    return {'halos': halos, 'dark_fraction': round(dark_fraction, 3), 'num_halos': len(halos)}

# Example run
G, metrics = run_toy_model()
dark = extract_dark_halos(G, metrics['min_w'])
print("Toy model metrics:", metrics)
print("Dark-matter fraction:", dark['dark_fraction'])
